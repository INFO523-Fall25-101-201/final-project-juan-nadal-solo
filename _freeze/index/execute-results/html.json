{
  "hash": "36b8d8e2fb64419dfe784a38be2a369a",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Are Movie Stars Worth Their Premiums?\"\nsubtitle: \"INFO 523 - Data Mining and Discovery - Final Project\"\nauthor:\n  - name: \"Juan Nadal\"\n    affiliations:\n      - name: \"College of Information Science, University of Arizona\"\nformat:\n   html:\n    code-tools: true\n    code-overflow: wrap\n    embed-resources: true\neditor: visual\nexecute:\n  warning: false\n  echo: true\njupyter: python3\n---\n\n::: {#setup .cell execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\nplt.style.use('seaborn-v0_8-whitegrid')\nsns.set_palette(\"husl\")\n\ndf = pd.read_csv('data/processed/full_dataset.csv')\nfeature_importance = pd.read_csv('data/processed/feature_importance_fixed.csv')\nmodel_comparison = pd.read_csv('data/processed/model_comparison_fixed.csv')\n\ntotal_movies = len(df)\nmovies_with_cast_data = len(df[df['cast_avg_roi'] > 0])\nstar_corr = df['cast_avg_roi'].corr(df['roi'])\nstar_r_squared = star_corr ** 2\n\nstar_power_rank = feature_importance[feature_importance['Feature'] == 'cast_avg_roi'].index[0] + 1\nstar_power_imp = feature_importance[feature_importance['Feature'] == 'cast_avg_roi']['Importance'].values[0]\nbudget_imp = feature_importance[feature_importance['Feature'] == 'budget_micro']['Importance'].values[0]\n\nalist_roi = df[df['star_tier'].isin(['Superstar', 'A-list'])]['roi']\nother_roi = df[~df['star_tier'].isin(['Superstar', 'A-list'])]['roi']\nt_stat, p_val = stats.ttest_ind(alist_roi, other_roi)\npooled_std = np.sqrt(((len(alist_roi)-1)*alist_roi.std()**2 + (len(other_roi)-1)*other_roi.std()**2) / (len(alist_roi) + len(other_roi) - 2))\ncohens_d = (alist_roi.mean() - other_roi.mean()) / pooled_std\n\nbest_model = model_comparison.loc[model_comparison['R2_Score'].idxmax()]\n```\n:::\n\n\n## Introduction\n\nThe entertainment industry is a billion-dollar sector that relies heavily on star power to drive box-office success. Studios pay top salaries, expecting A-list stars to ensure high returns. However, based on my experience, that's not always the case, and I find I enjoy lesser-known films that most people haven't heard of more than movies with a big cast.\n\nThis project aims to determine whether a star-studded cast or the surprise of a low-budget film with an unknown cast is more effective. Motivated by this gap, I wanted to see if movie stars are truly worth their premiums or if key factors like budget discipline and storytelling are the main contributors to ROI.\n\nUsing data mining techniques on 5,311 films spanning 1915–2017, I analyzed whether star power, measured by a cast's historical performance, better predicts success than factors such as release timing and franchise status. The goal was to move beyond industry anecdotes and see if the numbers confirm that execution matters more than fame.\n\n\n### Dataset\n\nThe analysis uses three merged Kaggle datasets: 5\\,311 movies spanning 1915-2017, representing $485.6 billion in revenue and $167.2 billion in budgets.\n\n**Key Variables:**\n\n| Variable | Description |\n|----------|-------------|\n| `roi` | Target: (Revenue - Budget) / Budget * 100 |\n| `cast_avg_roi` | Average historical ROI of cast members |\n| `budget_micro` | Binary flag for micro-budget films |\n| `vote_average` | Audience rating (0-10) |\n| `is_franchise` | Whether part of a franchise |\n| `star_tier` | Superstar, A-list, B-list, or Unknown |\n\n\n\n## Methodology\n\nI used a two-pronged approach: traditional statistics (correlation, ANOVA, t-test) and machine learning (6 regression models including XGBoost, Random Forest, and Lasso).\n\nCorrelation measures linear relationships. ANOVA compares means across star tiers. The t-test directly compares premium talent vs. others. Machine learning captures non-linear patterns and ranks feature importance.\n\nSix models were compared to ensure robust findings if multiple algorithms agree that star power ranks low, the conclusion is reliable.\n\n## Results\n\n### Statistical Evidence\n\n**Statistical Evidence: Correlation Analysis:** Correlation measures the linear relationship between two variables, ranging from -1 (perfect negative relationship) to +1 (perfect positive relationship). Values near zero indicate no meaningful relationship.\nWhen I examined what factors correlate with ROI, the results challenged conventional industry:\n\n| Feature | Correlation | Interpretation |\n|---------|-------------|----------------|\n| vote_average | 0.171 | Strongest positive—better audience ratings associate with slightly higher ROI |\n| revenue | 0.146 | Positive but misleading (ROI is calculated from revenue, so this is partially circular) |\n| budget | -0.135 | Negative—higher budgets tend to *reduce* ROI, not increase it |\n| cast_avg_roi | 0.078 | Very weak—star power barely correlates with movie ROI |\n| runtime | -0.029 | Near zero—film length has almost no relationship with returns |\n\n**What does a 0.078 correlation actually mean?**\n\nThe correlation squared tells us how much variance one variable explains in another. For star power:\n\n0.078² = 0.006, or **0.6%**\n\nThis means star power explains less than 1% of the variation in movie ROI. The other 99.4% is driven by factors unrelated to who's in the cast.\n\n**The Budget Paradox**\n\nThe most counterintuitive finding is budget's having a negative correlation (-0.135). Ideally, spending more should yield more however, higher budgets raise the threshold for success. A $200 million film needs massive returns just to break even, while a $5 million production can achieve extraordinary ROI with modest ticket sales. This is why budget discipline rather than budget size emerged as the top predictor in my machine learning models.\n\n**Why Stars Don't Move the Needle**\n\nIf star power truly drove financial success, there would be a stronger correlation of at least 0.3 to 0.5 a moderate to strong relationship. Instead, 0.078 is statistically negligible. For comparison, vote_average (audience ratings) correlates more than twice as strongly with ROI, suggesting that what audiences think of a film matters far more than who's in it.\n\nThe correlation analysis was my first indication that the industry's star-power assumption might be fundamentally flawed. The machine learning models would later confirm it.\n\n::: {#cell-correlation-heatmap .cell execution_count=2}\n``` {.python .cell-code}\nfig, ax = plt.subplots(figsize=(8, 6))\ncorr_matrix = df[['roi', 'cast_avg_roi', 'budget', 'vote_average', 'vote_count']].corr()\nsns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='RdBu_r', center=0, square=True, ax=ax)\nplt.title('Correlation Matrix: ROI and Key Predictors', fontweight='bold')\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Correlation Matrix](index_files/figure-html/correlation-heatmap-output-1.png){#correlation-heatmap width=632 height=565}\n:::\n:::\n\n\n**Hypothesis Testing: Statistical vs. Practical Significance**\n\nThe t-test addressed a specific question of whether there is a significant difference in ROI between movies with top-tier stars (historical ROI >150%) and those without.\n\nInitially, this would seem to be true because the films with top-tier stars had a 121% higher ROI, with a statistically significant p-value of 0.024.\nHowever, statistical significance does not equal practical relevance.\n\nThe effect size (Cohen's d) was only 0.14, which is considered negligible. This low figure indicates that the distributions overlap heavily across most films, with stars performing similarly to those without.\nThe 121% average isn't driven by consistent outperformance, but by massive outliers skewing the math. Although the p-value indicates a statistically significant difference, the small effect size suggests that stars are not reliable predictors of consistent returns but most liekly associated with infrequent, costly increases.\n\n::: {#cell-star-tier-boxplot .cell execution_count=3}\n``` {.python .cell-code}\nfig, ax = plt.subplots(figsize=(8, 5))\ntier_order = ['Superstar', 'A-list', 'B-list', 'Unknown/C-list']\nsns.boxplot(data=df[df['star_tier'].isin(tier_order)], x='star_tier', y='roi', order=tier_order, ax=ax)\nax.set_ylim(0, df['roi'].quantile(0.95))\nax.set_xlabel('Star Tier')\nax.set_ylabel('ROI (%)')\nax.set_title('ROI Distribution by Star Tier', fontweight='bold')\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![ROI by Star Tier](index_files/figure-html/star-tier-boxplot-output-1.png){#star-tier-boxplot width=758 height=469}\n:::\n:::\n\n\n### Machine Learning & Feature Importance\n\nTo move beyond simple correlations, I trained six machine learning models to identify which factors best predict ROI. The top performer was XGBoost (Extreme Gradient Boosting), an algorithm that builds sequential decision trees to capture complex patterns that simpler statistics often miss.\n\nTo ensure model validity, I excluded revenue-based variables to prevent target leakage. The final model achieved an R-squared of 33.7%, explaining roughly one-third of the variance in movie success.\n\nThe feature importance rankings quantified the disconnect between salary and value. Budget Discipline ranked as the #1 predictor (30.4% importance), while Star Power ranked 29th (1.12%). The data shows a 27-to-1 difference in impact, confirming that among the factors we can control, keeping budgets lean matters far more than who is on the poster.\n\n::: {#cell-feature-importance .cell execution_count=4}\n``` {.python .cell-code}\nfig, ax = plt.subplots(figsize=(10, 6))\ntop_features = feature_importance.head(15).iloc[::-1]\ncolors = ['#e74c3c' if 'cast_avg_roi' in f else '#3498db' for f in top_features['Feature']]\nax.barh(top_features['Feature'], top_features['Importance'] * 100, color=colors)\nax.set_xlabel('Importance (%)')\nax.set_title('Feature Importance (XGBoost, Revenue Excluded)', fontweight='bold')\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Feature Importance (Top 15)](index_files/figure-html/feature-importance-output-1.png){#feature-importance width=949 height=565}\n:::\n:::\n\n\n**Key Finding:** Budget category ranks #1 at 30\\.4% importance. Star power (`cast_avg_roi`) ranks at 1\\.12%. Budget is 27x more important than star power.\n\n## Final Thoughts\n\nMy analysis confirms that movie stars are overpaid relative to their ROI. While recognizable names generate buzz and simplify marketing, their premium salaries inflate budgets and drastically raise the break-even point for profitability.\n\nThe smarter investment prioritizes story and budget discipline. Studios like A24 and the horror genre demonstrate that compelling narratives and efficient production yield returns that massive blockbusters cannot match.\n\nThe data supports that star power shows minimal predictive value (r = 0.078; feature importance 1.1%). While films with stars show a slightly higher average ROI, the negligible effect size (d = 0.14) suggests this is driven by outliers rather than consistent performance. Stars don't guarantee returns; they just make the math harder.\n\nWhile the model has limitations explaining 34% of variance and predating the streaming era, the economic reality remains to maximize ROI, bet on the story, not the star.\n\n## Conclusion\n\nAcross 5\\,311 films, star power ranks 29 of 51 features at 1\\.1% importance. Budget discipline is 27x more important.\n\n**Recommendation:** Studios should prioritize budget management, franchise development, and audience engagement over celebrity salaries. Unknown actors may offer better risk-adjusted returns than expensive A-list talent.\n\n[Are Movie Stars Worth Their Premiums? - Presentation Recording](https://drive.google.com/file/d/1SSftKouaSFc6OTQPVkvTa477m4PisKmm/view)\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}